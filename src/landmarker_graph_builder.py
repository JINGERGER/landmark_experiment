#!/usr/bin/env python3
"""
Landmark Graph Builder Node
è®¢é˜…BEVç‰©ä½“æ£€æµ‹ç»“æœå’Œé‡Œç¨‹è®¡æ•°æ®ï¼Œæ„å»ºå…¨å±€åœ°æ ‡å›¾

Subscribes to: 
    /yolo11/bev/objects - BEVç‰©ä½“æ£€æµ‹ç»“æœ (BevObjectArray)
    /odom - é‡Œç¨‹è®¡æ•°æ® (Odometry)
    /camera/camera/color/image_raw - å½©è‰²å›¾åƒ (Image)
    
Publishes to:
    /landmark_graph/markers - åœ°æ ‡å›¾å¯è§†åŒ– (MarkerArray)
    /landmark_graph/data - åœ°æ ‡å›¾æ•°æ® (String - JSONæ ¼å¼)
"""

import rclpy
from rclpy.node import Node
from bev.msg import BevObjectArray, BevObject
from nav_msgs.msg import Odometry
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import String, Header
from geometry_msgs.msg import Point, Quaternion, Pose, Vector3
from sensor_msgs.msg import Image
import json
import numpy as np
import math
from datetime import datetime
import time
import cv2
from cv_bridge import CvBridge

class LandmarkGraphBuilder(Node):
    def __init__(self):
        super().__init__('landmark_graph_builder')
        
        # Declare parameters
        self.declare_parameter('bev_objects_topic', '/yolo11/bev/objects')
        self.declare_parameter('odom_topic', '/odom')
        self.declare_parameter('landmark_markers_topic', '/landmark_graph/markers')
        self.declare_parameter('landmark_data_topic', '/landmark_graph/data')
        self.declare_parameter('association_distance_threshold', 1.0)  # ç‰©ä½“å…³è”è·ç¦»é˜ˆå€¼(ç±³)
        self.declare_parameter('landmark_confidence_threshold', 0.6)   # åœ°æ ‡ç½®ä¿¡åº¦é˜ˆå€¼
        self.declare_parameter('min_observations', 2)                 # æœ€å°è§‚æµ‹æ¬¡æ•°
        self.declare_parameter('max_landmark_age', 30.0)              # åœ°æ ‡æœ€å¤§å­˜æ´»æ—¶é—´(ç§’)
        self.declare_parameter('publish_rate', 2.0)                   # å‘å¸ƒé¢‘ç‡(Hz)
        self.declare_parameter('enable_vlm_association', False)       # å¯ç”¨VLMå…³è”
        self.declare_parameter('vlm_model_name', 'gpt-4-vision-preview')  # VLMæ¨¡å‹åç§°
        self.declare_parameter('vlm_confidence_threshold', 0.7)       # VLMå…³è”ç½®ä¿¡åº¦é˜ˆå€¼
        self.declare_parameter('color_topic', '/camera/camera/color/image_raw')
        
        # Get parameters
        self.bev_objects_topic = self.get_parameter('bev_objects_topic').get_parameter_value().string_value
        self.odom_topic = self.get_parameter('odom_topic').get_parameter_value().string_value
        self.landmark_markers_topic = self.get_parameter('landmark_markers_topic').get_parameter_value().string_value
        self.landmark_data_topic = self.get_parameter('landmark_data_topic').get_parameter_value().string_value
        self.association_threshold = self.get_parameter('association_distance_threshold').get_parameter_value().double_value
        self.confidence_threshold = self.get_parameter('landmark_confidence_threshold').get_parameter_value().double_value
        self.min_observations = self.get_parameter('min_observations').get_parameter_value().integer_value
        self.max_age = self.get_parameter('max_landmark_age').get_parameter_value().double_value
        self.publish_rate = self.get_parameter('publish_rate').get_parameter_value().double_value
        self.vlm_enabled = self.get_parameter('enable_vlm_association').get_parameter_value().bool_value
        self.vlm_model = self.get_parameter('vlm_model_name').get_parameter_value().string_value
        self.vlm_confidence_threshold = self.get_parameter('vlm_confidence_threshold').get_parameter_value().double_value
        # è®¢é˜…å½©è‰²å›¾åƒè¯é¢˜ï¼ˆç”¨äºVLMå¤šæ¨¡æ€ï¼‰
        self.color_topic = self.get_parameter('color_topic').get_parameter_value().string_value
         
        # åœ°æ ‡å›¾æ•°æ®ç»“æ„
        self.landmarks = {}  # landmark_id: LandmarkData
        self.next_landmark_id = 1
        
        # æœºå™¨äººå½“å‰ä½å§¿
        self.robot_pose = None
        self.robot_orientation = None
        
        # æœ€æ–°çš„BEVæ£€æµ‹æ•°æ®
        self.latest_bev_objects = None
        self.last_bev_timestamp = None
        
        # å½©è‰²å›¾åƒå¤„ç†
        self.bridge = CvBridge()
        self.latest_color_image_path = None
        
        # Create subscribers
        self.bev_sub = self.create_subscription(
            BevObjectArray,
            self.bev_objects_topic,
            self.bev_objects_callback,
            10
        )
        
        self.odom_sub = self.create_subscription(
            Odometry,
            self.odom_topic,
            self.odom_callback,
            10
        )
        
        self.color_sub = self.create_subscription(
            Image,
            self.color_topic,
            self.color_image_callback,
            5
        )
        
        # Create publishers
        self.marker_pub = self.create_publisher(
            MarkerArray,
            self.landmark_markers_topic,
            10
        )
        
        self.data_pub = self.create_publisher(
            String,
            self.landmark_data_topic,
            10
        )
        
        # Timer for periodic publishing
        self.timer = self.create_timer(1.0 / self.publish_rate, self.publish_landmarks)
        
        self.get_logger().info(f"ğŸš€ Landmark Graph Builder initialized")
        self.get_logger().info(f"ğŸ“¥ Subscribing to BEV objects: {self.bev_objects_topic}")
        self.get_logger().info(f"ğŸ“¥ Subscribing to odometry: {self.odom_topic}")
        self.get_logger().info(f"ğŸ“¥ Subscribing to color images: {self.color_topic}")
        self.get_logger().info(f"ğŸ“¤ Publishing markers to: {self.landmark_markers_topic}")
        self.get_logger().info(f"ğŸ“¤ Publishing data to: {self.landmark_data_topic}")
        self.get_logger().info(f"ğŸ”§ Association threshold: {self.association_threshold}m")
        self.get_logger().info(f"ğŸ”§ Confidence threshold: {self.confidence_threshold}")
        self.get_logger().info(f"ğŸ”§ Min observations: {self.min_observations}")

    def odom_callback(self, msg):
        """å¤„ç†é‡Œç¨‹è®¡æ•°æ®ï¼Œæ›´æ–°æœºå™¨äººä½å§¿"""
        self.robot_pose = msg.pose.pose.position
        self.robot_orientation = msg.pose.pose.orientation
        
        # å¤„ç†æœ€æ–°çš„BEVæ£€æµ‹æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if self.latest_bev_objects is not None:
            self.process_bev_objects_with_odom(self.latest_bev_objects)
            self.latest_bev_objects = None

    def bev_objects_callback(self, msg):
        """å¤„ç†BEVç‰©ä½“æ£€æµ‹æ•°æ®"""
        self.latest_bev_objects = msg
        self.last_bev_timestamp = msg.header.stamp
        
        # å¦‚æœå·²æœ‰æœºå™¨äººä½å§¿ï¼Œç«‹å³å¤„ç†
        if self.robot_pose is not None:
            self.process_bev_objects_with_odom(msg)
            self.latest_bev_objects = None

    def color_image_callback(self, msg):
        """ä¿å­˜æœ€è¿‘ä¸€å¸§å½©è‰²å›¾åƒåˆ°æœ¬åœ°ï¼Œä¾›VLMä½¿ç”¨"""
        try:
            cv_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            save_path = f"/tmp/vlm_latest_color.jpg"
            cv2.imwrite(save_path, cv_img)
            self.latest_color_image_path = save_path
        except Exception as e:
            self.get_logger().warn(f"Failed to save color image: {e}")

    def process_bev_objects_with_odom(self, bev_msg):
        """å°†BEVæ£€æµ‹ç»“æœä¸é‡Œç¨‹è®¡æ•°æ®å…³è”ï¼Œæ›´æ–°åœ°æ ‡å›¾"""
        if self.robot_pose is None:
            return
        
        current_time = time.time()
        
        # è½¬æ¢æœºå™¨äººæœå‘ä¸ºæ¬§æ‹‰è§’
        robot_yaw = self.quaternion_to_yaw(self.robot_orientation)
        
        # å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„ç‰©ä½“
        for bev_obj in bev_msg.objects:
            if bev_obj.confidence < self.confidence_threshold:
                continue
                
            # å°†BEVåæ ‡è½¬æ¢ä¸ºå…¨å±€åæ ‡
            global_pos = self.bev_to_global(
                bev_obj.bev_position, 
                self.robot_pose, 
                robot_yaw
            )
            
            # æŸ¥æ‰¾æˆ–åˆ›å»ºåœ°æ ‡
            landmark_id = self.associate_or_create_landmark(
                global_pos, 
                bev_obj.class_name, 
                bev_obj.confidence,
                bev_obj.equivalent_diameter_m,
                current_time,
                bev_obj  # ä¼ é€’å®Œæ•´çš„BEVå¯¹è±¡ç»™VLMä½¿ç”¨
            )
            
            self.get_logger().debug(
                f"ğŸ¯ Object {bev_obj.class_name} at global ({global_pos[0]:.2f}, {global_pos[1]:.2f}) "
                f"-> landmark {landmark_id}"
            )
        
        # æ¸…ç†è¿‡æœŸåœ°æ ‡
        self.cleanup_old_landmarks(current_time)
        
        self.get_logger().info(f"ğŸ—ºï¸ Landmark graph updated: {len(self.landmarks)} landmarks")

    def bev_to_global(self, bev_position, robot_position, robot_yaw):
        """å°†BEVç›¸å¯¹åæ ‡è½¬æ¢ä¸ºå…¨å±€åæ ‡"""
        # BEVåæ ‡ç³»ï¼šx-å‰è¿›ï¼Œy-å·¦ä¾§
        bev_x = bev_position.x  # å‰è¿›è·ç¦»
        bev_y = bev_position.y  # å·¦ä¾§è·ç¦»
        
        # æ—‹è½¬åˆ°å…¨å±€åæ ‡ç³»
        cos_yaw = math.cos(robot_yaw)
        sin_yaw = math.sin(robot_yaw)
        
        # å…¨å±€åæ ‡
        global_x = robot_position.x + cos_yaw * bev_x - sin_yaw * bev_y
        global_y = robot_position.y + sin_yaw * bev_x + cos_yaw * bev_y
        
        return np.array([global_x, global_y])

    def associate_or_create_landmark(self, global_pos, class_name, confidence, size, timestamp, bev_obj=None):
        """å…³è”æˆ–åˆ›å»ºæ–°åœ°æ ‡ - æ”¯æŒVLMå¢å¼º"""
        # æŸ¥æ‰¾è·ç¦»æœ€è¿‘çš„åŒç±»åœ°æ ‡
        closest_landmark_id = None
        min_distance = float('inf')
        
        candidates = []  # å€™é€‰åœ°æ ‡åˆ—è¡¨ï¼Œç”¨äºVLMéªŒè¯
        
        for lid, landmark in self.landmarks.items():
            if landmark['class_name'] == class_name:
                distance = np.linalg.norm(global_pos - landmark['position'])
                if distance < min_distance:
                    min_distance = distance
                    closest_landmark_id = lid
                
                # æ”¶é›†æ‰€æœ‰åœ¨é˜ˆå€¼èŒƒå›´å†…çš„å€™é€‰è€…
                if distance < self.association_threshold * 2:  # æ‰©å¤§æœç´¢èŒƒå›´
                    candidates.append({
                        'id': lid,
                        'distance': distance,
                        'landmark': landmark
                    })
        
        # å¦‚æœæœ‰å¤šä¸ªå€™é€‰è€…ä¸”æœ‰å›¾åƒæ•°æ®ï¼Œä½¿ç”¨VLMéªŒè¯
        if len(candidates) > 1 and bev_obj is not None and hasattr(self, 'vlm_enabled') and self.vlm_enabled:
            best_match = self.vlm_associate_landmark(bev_obj, candidates, global_pos)
            if best_match is not None:
                self.update_landmark(best_match['id'], global_pos, confidence, size, timestamp, bev_obj)
                return best_match['id']
        
        # ä¼ ç»Ÿæ–¹æ³•ï¼šå¦‚æœæ‰¾åˆ°è¶³å¤Ÿè¿‘çš„åœ°æ ‡ï¼Œæ›´æ–°å®ƒ
        if closest_landmark_id is not None and min_distance < self.association_threshold:
            self.update_landmark(closest_landmark_id, global_pos, confidence, size, timestamp, bev_obj)
            return closest_landmark_id
        else:
            # åˆ›å»ºæ–°åœ°æ ‡
            return self.create_new_landmark(global_pos, class_name, confidence, size, timestamp, bev_obj)

    def create_new_landmark(self, global_pos, class_name, confidence, size, timestamp):
        """åˆ›å»ºæ–°åœ°æ ‡"""
        landmark_id = self.next_landmark_id
        self.next_landmark_id += 1
        
        self.landmarks[landmark_id] = {
            'id': landmark_id,
            'class_name': class_name,
            'position': global_pos.copy(),
            'confidence': confidence,
            'size': size,
            'observations': 1,
            'created_time': timestamp,
            'last_seen': timestamp,
            'position_history': [global_pos.copy()],
            'confidence_history': [confidence]
        }
        
        self.get_logger().info(f"âœ¨ Created new landmark {landmark_id}: {class_name} at ({global_pos[0]:.2f}, {global_pos[1]:.2f})")
        return landmark_id

    def update_landmark(self, landmark_id, global_pos, confidence, size, timestamp, bev_obj=None):
        """æ›´æ–°ç°æœ‰åœ°æ ‡"""
        landmark = self.landmarks[landmark_id]
        
        # å¢åŠ è§‚æµ‹æ¬¡æ•°
        landmark['observations'] += 1
        landmark['last_seen'] = timestamp
        
        # æ›´æ–°ä½ç½®ï¼ˆä½¿ç”¨åŠ æƒå¹³å‡ï¼‰
        alpha = 0.3  # æ–°è§‚æµ‹çš„æƒé‡
        landmark['position'] = (1 - alpha) * landmark['position'] + alpha * global_pos
        
        # æ›´æ–°ç½®ä¿¡åº¦ï¼ˆä½¿ç”¨æœ€å¤§å€¼æˆ–åŠ æƒå¹³å‡ï¼‰
        landmark['confidence'] = max(landmark['confidence'], confidence)
        
        # æ›´æ–°å°ºå¯¸
        landmark['size'] = (landmark['size'] + size) / 2
        
        # è®°å½•å†å²
        landmark['position_history'].append(global_pos.copy())
        landmark['confidence_history'].append(confidence)
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(landmark['position_history']) > 10:
            landmark['position_history'] = landmark['position_history'][-10:]
            landmark['confidence_history'] = landmark['confidence_history'][-10:]

    def cleanup_old_landmarks(self, current_time):
        """æ¸…ç†è¿‡æœŸåœ°æ ‡"""
        landmarks_to_remove = []
        
        for lid, landmark in self.landmarks.items():
            age = current_time - landmark['last_seen']
            if age > self.max_age:
                landmarks_to_remove.append(lid)
        
        for lid in landmarks_to_remove:
            removed_landmark = self.landmarks.pop(lid)
            self.get_logger().info(
                f"ğŸ—‘ï¸ Removed expired landmark {lid}: {removed_landmark['class_name']} "
                f"(age: {current_time - removed_landmark['last_seen']:.1f}s)"
            )

    def extract_vlm_features(self, bev_obj):
        """ä»BEVå¯¹è±¡ä¸­æå–VLMå¯ç”¨çš„ç‰¹å¾æè¿°"""
        if not bev_obj:
            return None
            
        features = {
            'description': f"A {bev_obj.class_name} object",
            'size_category': self.categorize_size(bev_obj.equivalent_diameter_m),
            'position_description': self.describe_position(bev_obj.bev_position),
            'confidence_level': self.categorize_confidence(bev_obj.confidence),
            'timestamp': time.time()
        }
        
        return features
    
    def merge_vlm_features(self, old_features, new_features):
        """åˆå¹¶VLMç‰¹å¾"""
        if not old_features:
            return new_features
            
        if not new_features:
            return old_features
        
        # ç®€å•çš„ç‰¹å¾åˆå¹¶ç­–ç•¥
        merged = old_features.copy()
        
        # æ›´æ–°æ—¶é—´æˆ³
        merged['timestamp'] = new_features['timestamp']
        
        # å¦‚æœç½®ä¿¡åº¦æé«˜ï¼Œæ›´æ–°æè¿°
        if new_features.get('confidence_level', 'low') > merged.get('confidence_level', 'low'):
            merged.update(new_features)
            
        return merged
    
    def categorize_size(self, diameter_m):
        """å°†å°ºå¯¸åˆ†ç±»ä¸ºå¯ç†è§£çš„æè¿°"""
        if diameter_m < 0.3:
            return "small"
        elif diameter_m < 1.0:
            return "medium"
        elif diameter_m < 2.0:
            return "large"
        else:
            return "very_large"
    
    def describe_position(self, bev_position):
        """æè¿°BEVä½ç½®"""
        x, y = bev_position.x, bev_position.y
        
        # è·ç¦»æè¿°
        distance = math.sqrt(x*x + y*y)
        if distance < 1.0:
            dist_desc = "very close"
        elif distance < 2.0:
            dist_desc = "close"
        elif distance < 4.0:
            dist_desc = "moderate distance"
        else:
            dist_desc = "far"
            
        # æ–¹å‘æè¿°
        if abs(y) < 0.5:  # åŸºæœ¬ç›´å‰æ–¹
            dir_desc = "directly ahead"
        elif y > 0:
            dir_desc = "to the left"
        else:
            dir_desc = "to the right"
            
        return f"{dist_desc}, {dir_desc}"
    
    def categorize_confidence(self, confidence):
        """å°†ç½®ä¿¡åº¦åˆ†ç±»"""
        if confidence < 0.5:
            return "low"
        elif confidence < 0.7:
            return "medium"
        elif confidence < 0.9:
            return "high"
        else:
            return "very_high"

    def publish_landmarks(self):
        """å‘å¸ƒåœ°æ ‡å›¾æ•°æ®å’Œå¯è§†åŒ–"""
        if not self.landmarks:
            return
        
        # å‘å¸ƒå¯è§†åŒ–æ ‡è®°
        self.publish_landmark_markers()
        
        # å‘å¸ƒåœ°æ ‡æ•°æ®
        self.publish_landmark_data()

    def publish_landmark_markers(self):
        """å‘å¸ƒåœ°æ ‡å¯è§†åŒ–æ ‡è®°"""
        marker_array = MarkerArray()
        current_time = self.get_clock().now().to_msg()
        
        for lid, landmark in self.landmarks.items():
            # åªå‘å¸ƒæœ‰è¶³å¤Ÿè§‚æµ‹æ¬¡æ•°çš„åœ°æ ‡
            if landmark['observations'] < self.min_observations:
                continue
                
            # åˆ›å»ºæ ‡è®°
            marker = Marker()
            marker.header.frame_id = "odom"  # ä½¿ç”¨é‡Œç¨‹è®¡åæ ‡ç³»
            marker.header.stamp = current_time
            marker.ns = "landmarks"
            marker.id = lid
            marker.type = Marker.CYLINDER
            marker.action = Marker.ADD
            
            # è®¾ç½®ä½ç½®
            marker.pose.position.x = landmark['position'][0]
            marker.pose.position.y = landmark['position'][1]
            marker.pose.position.z = 0.0
            marker.pose.orientation.w = 1.0
            
            # è®¾ç½®å°ºå¯¸ï¼ˆåŸºäºç‰©ä½“å¤§å°ï¼‰
            size = max(0.2, min(landmark['size'], 2.0))  # é™åˆ¶åœ¨0.2-2.0ç±³ä¹‹é—´
            marker.scale.x = size
            marker.scale.y = size
            marker.scale.z = 0.5
            
            # è®¾ç½®é¢œè‰²ï¼ˆåŸºäºç‰©ä½“ç±»åˆ«å’Œç½®ä¿¡åº¦ï¼‰
            color = self.get_landmark_color(landmark['class_name'])
            marker.color.r = color[0]
            marker.color.g = color[1]
            marker.color.b = color[2]
            marker.color.a = min(1.0, landmark['confidence'] + 0.3)
            
            marker.lifetime.sec = int(2.0 / self.publish_rate)  # æ ‡è®°ç”Ÿå­˜æ—¶é—´
            
            marker_array.markers.append(marker)
            
            # åˆ›å»ºæ–‡æœ¬æ ‡ç­¾
            text_marker = Marker()
            text_marker.header = marker.header
            text_marker.ns = "landmark_labels"
            text_marker.id = lid
            text_marker.type = Marker.TEXT_VIEW_FACING
            text_marker.action = Marker.ADD
            
            text_marker.pose.position.x = landmark['position'][0]
            text_marker.pose.position.y = landmark['position'][1]
            text_marker.pose.position.z = 1.0
            text_marker.pose.orientation.w = 1.0
            
            text_marker.scale.z = 0.3
            text_marker.color.r = 1.0
            text_marker.color.g = 1.0
            text_marker.color.b = 1.0
            text_marker.color.a = 1.0
            
            text_marker.text = f"{landmark['class_name']}\nID:{lid}\nObs:{landmark['observations']}"
            text_marker.lifetime.sec = int(2.0 / self.publish_rate)
            
            marker_array.markers.append(text_marker)
        
        self.marker_pub.publish(marker_array)

    def publish_landmark_data(self):
        """å‘å¸ƒåœ°æ ‡å›¾æ•°æ®"""
        landmark_data = {
            'timestamp': time.time(),
            'total_landmarks': len(self.landmarks),
            'active_landmarks': sum(1 for l in self.landmarks.values() if l['observations'] >= self.min_observations),
            'robot_position': {
                'x': float(self.robot_pose.x) if self.robot_pose else 0.0,
                'y': float(self.robot_pose.y) if self.robot_pose else 0.0
            },
            'landmarks': []
        }
        
        for lid, landmark in self.landmarks.items():
            if landmark['observations'] >= self.min_observations:
                landmark_info = {
                    'id': lid,
                    'class_name': landmark['class_name'],
                    'position': {
                        'x': float(landmark['position'][0]),
                        'y': float(landmark['position'][1])
                    },
                    'confidence': float(landmark['confidence']),
                    'size': float(landmark['size']),
                    'observations': landmark['observations'],
                    'age': time.time() - landmark['created_time']
                }
                landmark_data['landmarks'].append(landmark_info)
        
        # å‘å¸ƒJSONæ•°æ®
        data_msg = String()
        data_msg.data = json.dumps(landmark_data, indent=2)
        self.data_pub.publish(data_msg)

    def get_landmark_color(self, class_name):
        """æ ¹æ®ç‰©ä½“ç±»åˆ«è·å–é¢œè‰²"""
        colors = {
            'person': [0.0, 1.0, 0.0],      # ç»¿è‰²
            'car': [1.0, 0.0, 0.0],         # çº¢è‰²
            'truck': [1.0, 0.5, 0.0],       # æ©™è‰²
            'bus': [1.0, 1.0, 0.0],         # é»„è‰²
            'bicycle': [0.0, 0.0, 1.0],     # è“è‰²
            'motorcycle': [1.0, 0.0, 1.0],  # ç´«è‰²
            'bottle': [0.0, 1.0, 1.0],      # é’è‰²
            'chair': [0.5, 0.5, 0.5],       # ç°è‰²
            'table': [0.8, 0.4, 0.2],       # æ£•è‰²
        }
        return colors.get(class_name, [0.5, 0.5, 0.5])  # é»˜è®¤ç°è‰²

    def quaternion_to_yaw(self, quaternion):
        """å°†å››å…ƒæ•°è½¬æ¢ä¸ºåèˆªè§’"""
        siny_cosp = 2 * (quaternion.w * quaternion.z + quaternion.x * quaternion.y)
        cosy_cosp = 1 - 2 * (quaternion.y * quaternion.y + quaternion.z * quaternion.z)
        return math.atan2(siny_cosp, cosy_cosp)

    def vlm_associate_landmark(self, bev_obj, candidates, global_pos):
        """ä½¿ç”¨VLMè¿›è¡Œåœ°æ ‡å…³è”éªŒè¯"""
        try:
            # æ„å»ºVLMæŸ¥è¯¢
            query = self.build_vlm_query(bev_obj, candidates)
            
            # è°ƒç”¨VLM APIï¼ˆè¿™é‡Œæ˜¯ä¼ªä»£ç ï¼Œéœ€è¦æ ¹æ®å…·ä½“VLMå®ç°ï¼‰
            vlm_response = self.query_vlm(query)
            
            # è§£æVLMå“åº”
            best_match = self.parse_vlm_response(vlm_response, candidates)
            
            if best_match and best_match.get('confidence', 0) > self.vlm_confidence_threshold:
                self.get_logger().info(
                    f"ğŸ¤– VLM matched {bev_obj.class_name} with landmark {best_match['id']} "
                    f"(confidence: {best_match['confidence']:.2f})"
                )
                return best_match
            
        except Exception as e:
            self.get_logger().warn(f"âš ï¸ VLM association failed: {e}, falling back to traditional method")
        
        return None
    
    def build_vlm_query(self, bev_obj, candidates):
        """æ„å»ºVLMæŸ¥è¯¢"""
        # æ„å»ºæè¿°å½“å‰æ£€æµ‹ç‰©ä½“çš„æ–‡æœ¬
        current_description = {
            'class': bev_obj.class_name,
            'confidence': float(bev_obj.confidence),
            'size': f"{bev_obj.equivalent_diameter_m:.2f}m diameter",
            'position': f"({bev_obj.bev_position.x:.2f}, {bev_obj.bev_position.y:.2f})",
        }
        
        # æ„å»ºå€™é€‰åœ°æ ‡çš„æè¿°
        candidate_descriptions = []
        for candidate in candidates:
            landmark = candidate['landmark']
            desc = {
                'id': candidate['id'],
                'class': landmark['class_name'],
                'confidence': landmark['confidence'],
                'size': f"{landmark['size']:.2f}m",
                'observations': landmark['observations'],
                'age': f"{time.time() - landmark['created_time']:.1f}s",
                'distance': f"{candidate['distance']:.2f}m"
            }
            candidate_descriptions.append(desc)
        
        # æ„å»ºVLMæç¤º
        prompt = f"""
        I am performing landmark association for robot navigation. A new {current_description['class']} object has been detected:
        - Confidence: {current_description['confidence']:.2f}
        - Size: {current_description['size']}
        - BEV Position: {current_description['position']}
        
        Existing landmark candidates are:
        """
        
        for i, desc in enumerate(candidate_descriptions):
            prompt += f"""
        Candidate {i+1} (ID: {desc['id']}):
        - Class: {desc['class']}
        - Confidence: {desc['confidence']:.2f}
        - Size: {desc['size']}
        - Observations: {desc['observations']}
        - Age: {desc['age']}
        - Distance: {desc['distance']}
        """
        
        prompt += """
        Please determine which existing landmark the newly detected object most likely corresponds to based on:
        1. Object class must match
        2. Size similarity
        3. Spatial proximity (closer distance means more likely to be the same object)
        4. Temporal continuity (recently observed landmarks are more likely to be the same)
        
        Please respond in JSON format:
        {
            "best_match_id": <landmark ID or null>,
            "confidence": <confidence score 0.0-1.0>,
            "reasoning": "<brief reasoning process>"
        }
        
        If no suitable match exists, return best_match_id as null.
        """
        
        query = {
            'prompt': prompt,
            'current_object': current_description,
            'candidates': candidate_descriptions
        }
        # å¦‚æœæœ‰æœ€æ–°å½©è‰²å›¾åƒï¼ŒåŠ å…¥image_urlå­—æ®µï¼ˆæœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼‰
        if self.latest_color_image_path:
            query['image_url'] = f"file://{self.latest_color_image_path}"
        return query
    
    def query_vlm(self, query):
        """æŸ¥è¯¢VLM API"""
        # è¿™é‡Œæ˜¯VLM APIè°ƒç”¨çš„æ¥å£
        # å¯ä»¥é›†æˆOpenAI GPT-4V, Google Gemini Vision, Qwen, æˆ–æœ¬åœ°éƒ¨ç½²çš„VLM
        if self.vlm_model.startswith('gpt-4'):
            return self.query_openai_vlm(query)
        elif self.vlm_model.startswith('gemini'):
            return self.query_gemini_vlm(query)
        elif self.vlm_model.startswith('llava'):
            return self.query_local_vlm(query)
        elif self.vlm_model.startswith('qwen'):
            return self.query_qwen_vlm(query)
        else:
            raise ValueError(f"Unsupported VLM model: {self.vlm_model}")
    
    def query_openai_vlm(self, query):
        """è°ƒç”¨OpenAI GPT-4V API"""
        # ä¼ªä»£ç  - éœ€è¦å®‰è£… openai åŒ…
        try:
            import openai
            
            response = openai.ChatCompletion.create(
                model=self.vlm_model,
                messages=[
                    {
                        "role": "user",
                        "content": query['prompt']
                    }
                ],
                max_tokens=500,
                temperature=0.1  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
            )
            
            return response.choices[0].message.content
            
        except ImportError:
            self.get_logger().warn("OpenAI package not installed, VLM disabled")
            return None
        except Exception as e:
            self.get_logger().error(f"OpenAI API error: {e}")
            return None
    
    def query_gemini_vlm(self, query):
        """è°ƒç”¨Google Gemini Vision API"""
        # ä¼ªä»£ç  - éœ€è¦å®‰è£… google-generativeai åŒ…
        try:
            import google.generativeai as genai
            
            model = genai.GenerativeModel(self.vlm_model)
            response = model.generate_content(query['prompt'])
            
            return response.text
            
        except ImportError:
            self.get_logger().warn("Google GenerativeAI package not installed, VLM disabled")
            return None
        except Exception as e:
            self.get_logger().error(f"Gemini API error: {e}")
            return None
    
    def query_local_vlm(self, query):
        """è°ƒç”¨æœ¬åœ°VLMæ¨¡å‹ï¼ˆå¦‚LLaVAï¼‰"""
        # ä¼ªä»£ç  - å¯ä»¥é€šè¿‡HTTP APIè°ƒç”¨æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹
        try:
            import requests
            
            # å‡è®¾æœ¬åœ°VLMæœåŠ¡è¿è¡Œåœ¨localhost:8000
            response = requests.post(
                "http://localhost:8000/generate",
                json={
                    "prompt": query['prompt'],
                    "max_tokens": 500,
                    "temperature": 0.1
                },
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()['text']
            else:
                raise Exception(f"Local VLM API returned {response.status_code}")
                
        except ImportError:
            self.get_logger().warn("Requests package not installed, local VLM disabled")
            return None
        except Exception as e:
            self.get_logger().error(f"Local VLM error: {e}")
            return None
    
    def query_qwen_vlm(self, query):
        """è°ƒç”¨Qwen VLM API (Aliyun ç™¾ç‚¼)ï¼Œæ”¯æŒå¤šæ¨¡æ€ï¼ˆå›¾æ–‡ï¼‰è¾“å…¥"""
        try:
            import os
            from openai import OpenAI
            client = OpenAI(
                api_key=os.getenv("DASHSCOPE_API_KEY"),
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            )
            # åˆ¤æ–­æ˜¯å¦æœ‰å›¾ç‰‡URL
            image_url = query.get('image_url', None)
            if image_url:
                messages = [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": [
                        {"type": "image_url", "image_url": {"url": image_url}},
                        {"type": "text", "text": query['prompt']},
                    ]},
                ]
            else:
                messages = [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": query['prompt']},
                ]
            response = client.chat.completions.create(
                model=self.vlm_model,  # e.g., "qwen3-vl-plus"
                messages=messages,
                max_tokens=500,
                temperature=0.1
            )
            return response.choices[0].message.content
        except ImportError:
            self.get_logger().warn("openai package not installed, Qwen VLM disabled")
            return None
        except Exception as e:
            self.get_logger().error(f"Qwen API error: {e}")
            return None

    def parse_vlm_response(self, response_text, candidates):
        """è§£æVLMå“åº”"""
        if not response_text:
            return None
            
        try:
            import json
            
            # å°è¯•è§£æJSONå“åº”
            # å¤„ç†å¯èƒ½çš„markdownæ ¼å¼åŒ…è£…
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                json_str = response_text[start:end].strip()
            else:
                json_str = response_text.strip()
            
            result = json.loads(json_str)
            
            # éªŒè¯å“åº”æ ¼å¼
            if 'best_match_id' in result and 'confidence' in result:
                match_id = result['best_match_id']
                confidence = float(result['confidence'])
                reasoning = result.get('reasoning', 'No reasoning provided')
                
                # å¦‚æœæœ‰åŒ¹é…ï¼ŒéªŒè¯IDæ˜¯å¦åœ¨å€™é€‰åˆ—è¡¨ä¸­
                if match_id is not None:
                    for candidate in candidates:
                        if candidate['id'] == match_id:
                            return {
                                'id': match_id,
                                'confidence': confidence,
                                'reasoning': reasoning,
                                'candidate': candidate
                            }
                
                # æ²¡æœ‰åŒ¹é…çš„æƒ…å†µ
                return None
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            self.get_logger().warn(f"Failed to parse VLM response: {e}")
            self.get_logger().debug(f"Response text: {response_text}")
        
        return None

def main(args=None):
    rclpy.init(args=args)
    node = LandmarkGraphBuilder()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info("ğŸ›‘ Landmark Graph Builder shutting down...")
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
